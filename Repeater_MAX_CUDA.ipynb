{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Repeater_MAX_CUDA.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "epF1okM-Yj5q",
        "outputId": "57e15087-0fc1-4547-d3a9-e7849884fe70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y08mXtN0Ylcd",
        "outputId": "ef46b935-f639-4534-aa3e-b9125c122fab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
        "  print('and then re-execute this cell.')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov 18 12:02:01 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    25W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q7LjR_tAYlmO",
        "outputId": "65cf7c43-d0dc-4ce8-99b7-1516cae68e2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!gdown --id 1li8IE3TPGZv8nSGgoo6jKvBc-gksZVLi"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1li8IE3TPGZv8nSGgoo6jKvBc-gksZVLi\n",
            "To: /content/intention_repeater_max_cuda.cu\n",
            "\r  0% 0.00/15.9k [00:00<?, ?B/s]\r100% 15.9k/15.9k [00:00<00:00, 26.3MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZSZ8QdfYluN"
      },
      "source": [
        "!nvcc intention_repeater_max_cuda.cu -O3 -o intention_repeater_max_cuda"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pHxDYDqYl0c",
        "outputId": "78e25822-fd9b-4406-e827-bafb78ffa48e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/content/intention_repeater_max_cuda --help"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intention Repeater MAX CUDA v2.2 (c)2020 Thomas Sweet aka Anthro Teacher.\n",
            "CUDA and flags functionality by Karteek Sheri.\n",
            "Intention multiplying functionality by Thomas Sweet.\n",
            "\n",
            "Optional Flags:\n",
            "\ta) --gpu or -g\n",
            "\tb) --dur or -d\n",
            "\tc) --imem or -m\n",
            "\td) --intent or -i\n",
            "\te) --suffix or -s\n",
            "\tf) --help\n",
            "\n",
            "--gpu = GPU # to use. Default = 0.\n",
            "--dur = Duration in HH:MM:SS format. Example 00:01:00 to run for one minute. Default = \"Until Stopped.\"\n",
            "--imem = Specify how many GB of GPU RAM to use. Default = 1.0. Higher amount produces a faster repeat rate, but takes longer to load into memory.\n",
            "--intent = Intention. Default = Prompt the user for intention.\n",
            "--suffix = Specify Hz or Exp. Exp = Exponent (ex. 1.313x10^15). Hz (ex. 1.313PHz). Default = Hz\n",
            "--help = Display this help.\n",
            "\n",
            "Example automated usage: intention_repeater_max_cuda.exe --gpu 0 --dur 00:01:00 --imem 1.0 --suffix hz --intent \"I am calm.\"\n",
            "Default usage: intention_repeater_max_cuda.exe\n",
            "\n",
            "gitHub Repository: https://github.com/tsweet77/repeater-max-cuda\n",
            "Forum: https://forums.intentionrepeater.com\n",
            "Website: https://www.intentionrepeater.com\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsBjKi_JZH72",
        "outputId": "1867b5e1-32bb-4ab6-9176-c5573eb3f4ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!/content/intention_repeater_max_cuda --dur 00:00:01 --imem 0.01 --intent \"I am calm.\""
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Intention Repeater MAX CUDA v2.2 created by Thomas Sweet aka Anthro Teacher.\n",
            "CUDA and flags functionality by Karteek Sheri.\n",
            "Intention multiplying functionality by Thomas Sweet.\n",
            "This software comes with no guarantees or warranty of any kind and is for entertainment purposes only.\n",
            "Press Ctrl-C to quit.\n",
            "\n",
            "Loading intention into memory.\n",
            "GPU 0 is selected.\n",
            "[00:00:01] (720.563T / 720.563THz): I am calm.     \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
